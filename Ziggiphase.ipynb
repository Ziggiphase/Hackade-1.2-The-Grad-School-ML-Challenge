{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f73dc7",
   "metadata": {},
   "source": [
    "# üéì From Scores to Seats: The Grad School ML Challenge\n",
    "\n",
    "Welcome to the starter notebook for this beginner-friendly data science hackathon! In this challenge, your goal is to build a machine learning model that can predict whether a student will be admitted into a graduate program based on their academic profile.\n",
    "\n",
    "This notebook will walk you through a simple end-to-end pipeline:\n",
    "- Loading and exploring the data\n",
    "- Preprocessing\n",
    "- Training a baseline model\n",
    "- Making predictions\n",
    "- Preparing a submission\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Files\n",
    "- `train.csv`: Training data (features + target)\n",
    "- `test.csv`: Test data (features only)\n",
    "- `SampleSubmission.csv`: Format for submitting predictions\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Target Variable\n",
    "- `Admitted`: 1 if the student was admitted, 0 otherwise\n",
    "\n",
    "Let's get started! üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Load the Data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"SampleSubmission.csv\")\n",
    "\n",
    "# Peek at the data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a948a17",
   "metadata": {},
   "source": [
    "## üîç Exploratory Data Analysis (EDA)\n",
    "Let‚Äôs explore the training data to understand the features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34692f",
   "metadata": {},
   "source": [
    "### üè∑Ô∏è Encoding 'Location'\n",
    "\n",
    "We used **one-hot encoding** to convert the categorical `Location` column into numeric format. This creates binary columns for each unique location (excluding one to avoid redundancy):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81d95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c41623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9012699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numeric values with the mean of each column\n",
    "numeric_cols = ['GRE Score', 'TOEFL Score', 'SOP', 'CGPA']\n",
    "train[numeric_cols] = train[numeric_cols].fillna(train[numeric_cols].mean())\n",
    "\n",
    "# Double check to confirm missing values are handled\n",
    "print(\"Remaining missing values:\", train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13589ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numeric values with the mean of each column\n",
    "numeric_cols = ['GRE Score', 'TOEFL Score', 'SOP', 'CGPA']\n",
    "test[numeric_cols] = test[numeric_cols].fillna(test[numeric_cols].mean())\n",
    "\n",
    "# Double check to confirm missing values are handled\n",
    "print(\"Remaining missing values:\", test.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7cbdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd77aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy variables for one-hot encoding\n",
    "train = pd.get_dummies(train, columns=['Location'], dtype=int, drop_first=True)\n",
    "test = pd.get_dummies(test, columns=['Location'], dtype=int, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ad0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable\n",
    "sns.countplot(x='Admitted', data=train)\n",
    "plt.title(\"Admission Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73efc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of key features\n",
    "num_features = ['GRE Score', 'TOEFL Score', 'CGPA']\n",
    "for col in num_features:\n",
    "    sns.histplot(train[col], kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114dbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = train.drop(columns=['Admitted', \"ID\"])\n",
    "y = train['Admitted']\n",
    "\n",
    "# Split into train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f83242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing lazypredict to run multiple models on the data\n",
    "!pip install lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "model = LazyClassifier()\n",
    "alg, mod = model.fit(X_train, X_val, y_train, y_val)\n",
    "print(alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c386a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using LightGBM with the Dropouts meet Multiple Additive Regression Trees boosting type\n",
    "!pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(boosting_type='dart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bfe1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Evaluate Model on Validation Set\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Accuracy score\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e1af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "importances.sort_values().plot(kind='barh')\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b7174",
   "metadata": {},
   "source": [
    "## üöÄ Predictions on Test Set\n",
    "Let‚Äôs predict on the test set and generate a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9744c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numeric values with the mean of each column\n",
    "numeric_cols = ['GRE Score', 'TOEFL Score', 'SOP', 'CGPA']\n",
    "test[numeric_cols] = test[numeric_cols].fillna(test[numeric_cols].mean())\n",
    "\n",
    "# Double check to confirm missing values are handled\n",
    "print(\"Remaining missing values:\", test.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test.drop(\"ID\", axis=1))\n",
    "\n",
    "# Prepare submission\n",
    "submission = sample_submission.copy()\n",
    "submission['Admitted'] = test_predictions\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('lgbm2_submission.csv', index=False)\n",
    "print(\"Submission file saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76048542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
